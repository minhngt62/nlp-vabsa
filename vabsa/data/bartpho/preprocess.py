{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport re\nimport json\nimport string\nimport emoji\nimport pandas as pd\n\ndef normalize_money(sent):\n    return re.sub(r'\\d+((,|.)\\d)?[k|m|b](/)?', 'gi√° ', sent)\n\ndef normalize_time(sent):\n    return re.sub(r'\\d+(\\s)?(h|gi·ªù)(\\s)?(\\d+)?', 'gi·ªù ', sent)\n\ndef normalize_hastag(sent):\n    return re.sub(r'#+\\w+', 'tag', sent)\n\ndef normalize_HTML(text):\n    return re.sub(r'<[^>]*>', '', text)\n\ndef normalize_website(sent):\n    result = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', 'website', sent)\n    return re.sub(r'\\w+(\\.(com|vn|me))+((\\/+([\\.\\w\\_\\-]+)?)+)?', 'website', result)\n\ndef normalize_emoji(sent):\n    return emoji.demojize(sent)\n\ndef normalize_elongate(sent):\n    patern = r'(.)\\1{1,}'\n    result = sent\n    while(re.search(patern, result) != None):\n        repeat_char = re.search(patern, result)\n        result = result.replace(repeat_char[0], repeat_char[1])\n    return result\n\ndef remove_number(sent):\n    return re.sub(r'[0-9]+', '', sent)\n\ndef remove_punct(text):\n    '''\n    This funtion replaces punctuations in texts for easier handling\n    '''\n    text = text.replace(\";\", \",\").replace(\"‚Äú\", \" \").replace(\"‚Äù\", \" \")\n    text = \"\".join(\n        [\n            c\n            if c.isalpha() or c.isdigit() or c in [\",\",\".\"]\n            else \" \"\n            for c in text\n        ]\n    )\n    text = \" \".join(text.split())\n    return text\n\ndef normalize_acronyms(sent):\n    text = sent\n    replace_list = {\n        '√¥ k√™i': ' ok ', 'okie': ' ok ', ' o k√™ ': ' ok ', 'okey': ' ok ', '√¥k√™': ' ok ',\n        'oki': ' ok ', ' oke ':  ' ok ',' okay':' ok ','ok√™':' ok ',' tks ': u' c√°m ∆°n ',\n        'thks': u' c√°m ∆°n ', 'thanks': u' c√°m ∆°n ', 'ths': u' c√°m ∆°n ', 'thank': u' c√°m ∆°n ',\n        '^_^': 't√≠ch c·ª±c', ':)': 't√≠ch c·ª±c', ':(': 'ti√™u c·ª±c', '‚ù§Ô∏è': 't√≠ch c·ª±c', 'üëç': 't√≠ch c·ª±c',\n        'üéâ': 't√≠ch c·ª±c', 'üòÄ': 't√≠ch c·ª±c', 'üòç': 't√≠ch c·ª±c', 'üòÇ': 't√≠ch c·ª±c', 'ü§ó': 't√≠ch c·ª±c',\n        'üòô': 't√≠ch c·ª±c', 'üôÇ': 't√≠ch c·ª±c', 'üòî': 'ti√™u c·ª±c', 'üòì': 'ti√™u c·ª±c', '‚≠ê': 'star', \n        '*': 'star', 'üåü': 'star','kg ': u' kh√¥ng ','not': u' kh√¥ng ', u' kg ': u' kh√¥ng ',\n        '\"k ': u' kh√¥ng ',' kh ':u' kh√¥ng ','k√¥':u' kh√¥ng ','hok':u' kh√¥ng ',' kp ': u' kh√¥ng ph·∫£i ',\n        u' k√¥ ': u' kh√¥ng ', '\"ko ': u' kh√¥ng ', u' ko ': u' kh√¥ng ', u' k ': u' kh√¥ng ',\n        'khong': u' kh√¥ng ', u' hok ': u' kh√¥ng ','he he': ' t√≠ch c·ª±c ','hehe': ' t√≠ch c·ª±c ',\n        'hihi': ' t√≠ch c·ª±c ', 'haha': ' t√≠ch c·ª±c ', 'hjhj': ' t√≠ch c·ª±c ',' lol ': ' ti√™u c·ª±c ',\n        ' cc ': ' ti√™u c·ª±c ','cute': u' d·ªÖ th∆∞∆°ng ','huhu': ' ti√™u c·ª±c ', ' vs ': u' v·ªõi ', 'wa': ' qu√° ', 'w√°': u' qu√°', 'j': u' g√¨ ', '‚Äú': ' ',\n        ' sz ': u' c·ª° ', 'size': u' c·ª° ', u' ƒëx ': u' ƒë∆∞·ª£c ', 'dk': u' ƒë∆∞·ª£c ', 'dc': u' ƒë∆∞·ª£c ', 'ƒëk': u' ƒë∆∞·ª£c ',\n        'ƒëc': u' ƒë∆∞·ª£c ','authentic': u' chu·∫©n ch√≠nh h√£ng ',u' aut ': u' chu·∫©n ch√≠nh h√£ng ', u' auth ': u' chu·∫©n ch√≠nh h√£ng ', 'thick': u' t√≠ch c·ª±c ', 'store': u' c·ª≠a h√†ng ',\n        'shop': u' c·ª≠a h√†ng ', 'sp': u' s·∫£n ph·∫©m ', 'gud': u' t·ªët ','god': u' t·ªët ','wel done':' t·ªët ', 'good': u' t·ªët ', 'g√∫t': u' t·ªët ',\n        's·∫•u': u' x·∫•u ','gut': u' t·ªët ', u' tot ': u' t·ªët ', u' nice ': u' t·ªët ', 'perfect': 'r·∫•t t·ªët', 'bt': u' b√¨nh th∆∞·ªùng ',\n        'time': u' th·ªùi gian ', 'q√°': u' qu√° ', u' ship ': u' giao h√†ng ', u' m ': u' m√¨nh ', u' mik ': u' m√¨nh ',\n        '√™Ãâ': '·ªÉ', 'product': 's·∫£n ph·∫©m', 'quality': 'ch·∫•t l∆∞·ª£ng','chat':' ch·∫•t ', 'excelent': 'ho√†n h·∫£o', 'bad': 't·ªá','fresh': ' t∆∞∆°i ','sad': ' t·ªá ',\n        'date': u' h·∫°n s·ª≠ d·ª•ng ', 'hsd': u' h·∫°n s·ª≠ d·ª•ng ','quickly': u' nhanh ', 'quick': u' nhanh ','fast': u' nhanh ','delivery': u' giao h√†ng ',u' s√≠p ': u' giao h√†ng ',\n        'beautiful': u' ƒë·∫πp tuy·ªát v·ªùi ', u' tl ': u' tr·∫£ l·ªùi ', u' r ': u' r·ªìi ', u' shopE ': u' c·ª≠a h√†ng ',u' order ': u' ƒë·∫∑t h√†ng ',\n        'ch·∫•t lg': u' ch·∫•t l∆∞·ª£ng ',u' sd ': u' s·ª≠ d·ª•ng ',u' dt ': u' ƒëi·ªán tho·∫°i ',u' nt ': u' nh·∫Øn tin ',u' tl ': u' tr·∫£ l·ªùi ',u' s√†i ': u' x√†i ',u'bjo':u' bao gi·ªù ',\n        'thik': u' th√≠ch ',u' sop ': u' c·ª≠a h√†ng ', ' fb ': ' facebook ', ' face ': ' facebook ', ' very ': u' r·∫•t ',u'qu·∫£ ng ':u' qu·∫£ng  ',\n        'dep': u' ƒë·∫πp ',u' xau ': u' x·∫•u ','delicious': u' ngon ', u'h√†g': u' h√†ng ', u'q·ªßa': u' qu·∫£ ',\n        'iu': u' y√™u ','fake': u' gi·∫£ m·∫°o ', 'trl': 'tr·∫£ l·ªùi', '><': u' t√≠ch c·ª±c ', \" view \": \" t·∫ßm nh√¨n \", \n        ' por ': u' t·ªá ',' poor ': u' t·ªá ', 'ib':u' nh·∫Øn tin ', 'rep':u' tr·∫£ l·ªùi ',u'fback':' feedback ','fedback':' feedback '\n    }\n    \n    for k, v in replace_list.items():\n        text = text.replace(k, v)\n    return text\n\ndef normalize(sent):\n    #result = standardize_sentence_typing(sent)\n    result = normalize_hastag(sent)\n    result = normalize_website(result)\n    result = normalize_HTML(result)\n    result = normalize_acronyms(result)\n    result = normalize_emoji(result)\n    result = result.lower()\n    result = normalize_time(result)\n    result = normalize_money(result)\n    result = normalize_elongate(result)\n    result = normalize_acronyms(result)\n    result = remove_number(result)\n    result = remove_punct(result)\n    result = result.replace(\",.\", \".\")\n    result = re.sub(r'\\s+', ' ', result).strip() # Remove extra whitespace\n    return result\n\ndef tokenize(sent, f):\n    return f(sent)","metadata":{"_uuid":"a8e5152f-4ed8-42ed-8c4f-57ce5ee92b71","_cell_guid":"7900b856-38b4-4a7c-bcd4-9ad1fae8020e","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}