{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Seq2Seq Model Training and Testing"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Prepare"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-06-28T09:52:09.488925Z","iopub.status.busy":"2023-06-28T09:52:09.488243Z","iopub.status.idle":"2023-06-28T09:52:33.741423Z","shell.execute_reply":"2023-06-28T09:52:33.740226Z","shell.execute_reply.started":"2023-06-28T09:52:09.488889Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: simpletransformers in /opt/conda/lib/python3.10/site-packages (0.63.11)\n","Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from simpletransformers) (1.23.5)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from simpletransformers) (2.28.2)\n","Requirement already satisfied: tqdm>=4.47.0 in /opt/conda/lib/python3.10/site-packages (from simpletransformers) (4.64.1)\n","Requirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from simpletransformers) (2023.5.5)\n","Requirement already satisfied: transformers>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from simpletransformers) (4.30.1)\n","Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (from simpletransformers) (2.1.0)\n","Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from simpletransformers) (1.10.1)\n","Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from simpletransformers) (1.2.2)\n","Requirement already satisfied: seqeval in /opt/conda/lib/python3.10/site-packages (from simpletransformers) (1.2.2)\n","Requirement already satisfied: tensorboard in /opt/conda/lib/python3.10/site-packages (from simpletransformers) (2.12.3)\n","Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from simpletransformers) (1.5.3)\n","Requirement already satisfied: tokenizers in /opt/conda/lib/python3.10/site-packages (from simpletransformers) (0.13.3)\n","Requirement already satisfied: wandb>=0.10.32 in /opt/conda/lib/python3.10/site-packages (from simpletransformers) (0.15.4)\n","Requirement already satisfied: streamlit in /opt/conda/lib/python3.10/site-packages (from simpletransformers) (1.24.0)\n","Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from simpletransformers) (0.1.99)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers>=4.6.0->simpletransformers) (3.12.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.6.0->simpletransformers) (0.15.1)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.6.0->simpletransformers) (21.3)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.6.0->simpletransformers) (5.4.1)\n","Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.6.0->simpletransformers) (0.3.1)\n","Requirement already satisfied: Click!=8.0.0,>=7.0 in /opt/conda/lib/python3.10/site-packages (from wandb>=0.10.32->simpletransformers) (8.1.3)\n","Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb>=0.10.32->simpletransformers) (3.1.31)\n","Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb>=0.10.32->simpletransformers) (5.9.3)\n","Requirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb>=0.10.32->simpletransformers) (1.25.1)\n","Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb>=0.10.32->simpletransformers) (0.4.0)\n","Requirement already satisfied: pathtools in /opt/conda/lib/python3.10/site-packages (from wandb>=0.10.32->simpletransformers) (0.1.2)\n","Requirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb>=0.10.32->simpletransformers) (1.3.2)\n","Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb>=0.10.32->simpletransformers) (59.8.0)\n","Requirement already satisfied: appdirs>=1.4.3 in /opt/conda/lib/python3.10/site-packages (from wandb>=0.10.32->simpletransformers) (1.4.4)\n","Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb>=0.10.32->simpletransformers) (3.20.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->simpletransformers) (2.1.1)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->simpletransformers) (3.4)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->simpletransformers) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->simpletransformers) (2023.5.7)\n","Requirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets->simpletransformers) (11.0.0)\n","Requirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from datasets->simpletransformers) (0.3.6)\n","Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets->simpletransformers) (3.2.0)\n","Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets->simpletransformers) (0.70.14)\n","Requirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from datasets->simpletransformers) (2023.6.0)\n","Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets->simpletransformers) (3.8.4)\n","Requirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets->simpletransformers) (0.18.0)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas->simpletransformers) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->simpletransformers) (2023.3)\n","Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->simpletransformers) (1.2.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->simpletransformers) (3.1.0)\n","Requirement already satisfied: altair<6,>=4.0 in /opt/conda/lib/python3.10/site-packages (from streamlit->simpletransformers) (5.0.1)\n","Requirement already satisfied: blinker<2,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from streamlit->simpletransformers) (1.6.2)\n","Requirement already satisfied: cachetools<6,>=4.0 in /opt/conda/lib/python3.10/site-packages (from streamlit->simpletransformers) (4.2.4)\n","Requirement already satisfied: importlib-metadata<7,>=1.4 in /opt/conda/lib/python3.10/site-packages (from streamlit->simpletransformers) (5.2.0)\n","Requirement already satisfied: pillow<10,>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from streamlit->simpletransformers) (9.5.0)\n","Requirement already satisfied: pympler<2,>=0.9 in /opt/conda/lib/python3.10/site-packages (from streamlit->simpletransformers) (1.0.1)\n","Requirement already satisfied: rich<14,>=10.11.0 in /opt/conda/lib/python3.10/site-packages (from streamlit->simpletransformers) (12.6.0)\n","Requirement already satisfied: tenacity<9,>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from streamlit->simpletransformers) (8.2.2)\n","Requirement already satisfied: toml<2 in /opt/conda/lib/python3.10/site-packages (from streamlit->simpletransformers) (0.10.2)\n","Requirement already satisfied: typing-extensions<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from streamlit->simpletransformers) (4.5.0)\n","Requirement already satisfied: tzlocal<5,>=1.1 in /opt/conda/lib/python3.10/site-packages (from streamlit->simpletransformers) (4.3.1)\n","Requirement already satisfied: validators<1,>=0.2 in /opt/conda/lib/python3.10/site-packages (from streamlit->simpletransformers) (0.20.0)\n","Requirement already satisfied: pydeck<1,>=0.1.dev5 in /opt/conda/lib/python3.10/site-packages (from streamlit->simpletransformers) (0.8.1b0)\n","Requirement already satisfied: tornado<7,>=6.0.3 in /opt/conda/lib/python3.10/site-packages (from streamlit->simpletransformers) (6.3.1)\n","Requirement already satisfied: watchdog in /opt/conda/lib/python3.10/site-packages (from streamlit->simpletransformers) (3.0.0)\n","Requirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.10/site-packages (from tensorboard->simpletransformers) (1.4.0)\n","Requirement already satisfied: grpcio>=1.48.2 in /opt/conda/lib/python3.10/site-packages (from tensorboard->simpletransformers) (1.51.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard->simpletransformers) (2.17.3)\n","Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard->simpletransformers) (1.0.0)\n","Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard->simpletransformers) (3.4.3)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard->simpletransformers) (0.7.0)\n","Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard->simpletransformers) (2.3.6)\n","Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.10/site-packages (from tensorboard->simpletransformers) (0.40.0)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit->simpletransformers) (3.1.2)\n","Requirement already satisfied: jsonschema>=3.0 in /opt/conda/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit->simpletransformers) (4.17.3)\n","Requirement already satisfied: toolz in /opt/conda/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit->simpletransformers) (0.12.0)\n","Requirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb>=0.10.32->simpletransformers) (1.16.0)\n","Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->simpletransformers) (23.1.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->simpletransformers) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->simpletransformers) (4.0.2)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->simpletransformers) (1.9.1)\n","Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->simpletransformers) (1.3.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->simpletransformers) (1.3.1)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb>=0.10.32->simpletransformers) (4.0.10)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard->simpletransformers) (0.2.7)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard->simpletransformers) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard->simpletransformers) (1.3.1)\n","Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata<7,>=1.4->streamlit->simpletransformers) (3.15.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers>=4.6.0->simpletransformers) (3.0.9)\n","Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from rich<14,>=10.11.0->streamlit->simpletransformers) (0.9.1)\n","Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /opt/conda/lib/python3.10/site-packages (from rich<14,>=10.11.0->streamlit->simpletransformers) (2.15.1)\n","Requirement already satisfied: pytz-deprecation-shim in /opt/conda/lib/python3.10/site-packages (from tzlocal<5,>=1.1->streamlit->simpletransformers) (0.1.0.post0)\n","Requirement already satisfied: decorator>=3.4.0 in /opt/conda/lib/python3.10/site-packages (from validators<1,>=0.2->streamlit->simpletransformers) (5.1.1)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard->simpletransformers) (2.1.2)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb>=0.10.32->simpletransformers) (5.0.0)\n","Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->simpletransformers) (0.19.3)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->simpletransformers) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard->simpletransformers) (3.2.2)\n","Requirement already satisfied: tzdata in /opt/conda/lib/python3.10/site-packages (from pytz-deprecation-shim->tzlocal<5,>=1.1->streamlit->simpletransformers) (2023.3)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mRequirement already satisfied: pyvi in /opt/conda/lib/python3.10/site-packages (0.1.1)\n","Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from pyvi) (1.2.2)\n","Requirement already satisfied: sklearn-crfsuite in /opt/conda/lib/python3.10/site-packages (from pyvi) (0.3.6)\n","Requirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->pyvi) (1.23.5)\n","Requirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->pyvi) (1.10.1)\n","Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->pyvi) (1.2.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->pyvi) (3.1.0)\n","Requirement already satisfied: python-crfsuite>=0.8.3 in /opt/conda/lib/python3.10/site-packages (from sklearn-crfsuite->pyvi) (0.9.9)\n","Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from sklearn-crfsuite->pyvi) (1.16.0)\n","Requirement already satisfied: tabulate in /opt/conda/lib/python3.10/site-packages (from sklearn-crfsuite->pyvi) (0.9.0)\n","Requirement already satisfied: tqdm>=2.0 in /opt/conda/lib/python3.10/site-packages (from sklearn-crfsuite->pyvi) (4.64.1)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["!pip install simpletransformers\n","!pip install pyvi"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-06-28T09:52:33.743924Z","iopub.status.busy":"2023-06-28T09:52:33.743229Z","iopub.status.idle":"2023-06-28T09:52:33.750128Z","shell.execute_reply":"2023-06-28T09:52:33.749261Z","shell.execute_reply.started":"2023-06-28T09:52:33.743884Z"},"trusted":true},"outputs":[],"source":["from vabsa.bartpho.preprocess import normalize, tokenize\n","from vabsa.bartpho.utils import tag_dict, polarity_dict, polarity_list, tags, eng_tags, eng_polarity, detect_labels, no_polarity, no_tag\n","from vabsa.bartpho.utils import predict, predict_df, predict_detect, predict_df_detect\n","from pyvi.ViTokenizer import tokenize as model_tokenize"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-06-28T09:52:33.751560Z","iopub.status.busy":"2023-06-28T09:52:33.751181Z","iopub.status.idle":"2023-06-28T09:52:33.763773Z","shell.execute_reply":"2023-06-28T09:52:33.762899Z","shell.execute_reply.started":"2023-06-28T09:52:33.751498Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["True\n"]}],"source":["import json\n","import logging\n","import math\n","import os\n","import random\n","import warnings\n","from dataclasses import asdict\n","from multiprocessing import Pool, cpu_count\n","from pathlib import Path\n","\n","import numpy as np\n","import pandas as pd\n","import torch\n","from tensorboardX import SummaryWriter\n","from torch.nn.utils.rnn import pad_sequence\n","from torch.utils.data import DataLoader, Dataset, RandomSampler, SequentialSampler\n","from torch.utils.data.distributed import DistributedSampler\n","from tqdm.auto import tqdm, trange\n","from transformers import (\n","    AdamW,\n","    AutoConfig,\n","    AutoModel,\n","    AutoTokenizer,\n","    MBartConfig,\n","    MBartForConditionalGeneration,\n","    MBartTokenizer,\n","    get_linear_schedule_with_warmup,\n",")\n","\n","#from simpletransformers.config.global_args import global_args\n","from simpletransformers.config.model_args import Seq2SeqArgs\n","from simpletransformers.seq2seq.seq2seq_utils import Seq2SeqDataset, SimpleSummarizationDataset\n","\n","try:\n","    import wandb\n","\n","    wandb_available = True\n","except ImportError:\n","    wandb_available = False\n","print(wandb_available)\n","logger = logging.getLogger(__name__)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Model"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-06-28T09:52:33.765636Z","iopub.status.busy":"2023-06-28T09:52:33.764949Z","iopub.status.idle":"2023-06-28T09:52:33.775629Z","shell.execute_reply":"2023-06-28T09:52:33.774736Z","shell.execute_reply.started":"2023-06-28T09:52:33.765602Z"},"trusted":true},"outputs":[],"source":["MODEL_CLASSES = {\n","    \"auto\": (AutoConfig, AutoModel, AutoTokenizer),\n","    #\"mbart\": (MBartConfig, MBartForConditionalGeneration, MBartTokenizer),\n","    \"bartpho\": (MBartConfig, MBartForConditionalGeneration, AutoTokenizer)\n","}"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-06-28T09:52:33.778040Z","iopub.status.busy":"2023-06-28T09:52:33.777310Z","iopub.status.idle":"2023-06-28T09:52:33.847234Z","shell.execute_reply":"2023-06-28T09:52:33.846250Z","shell.execute_reply.started":"2023-06-28T09:52:33.777999Z"},"trusted":true},"outputs":[],"source":["class Seq2SeqModel:\n","    def __init__(\n","        self,\n","        encoder_decoder_type=None,\n","        encoder_decoder_name=None,\n","        config=None,\n","        args=None,\n","        use_cuda=True,\n","        cuda_device=0,\n","        **kwargs,\n","    ):\n","\n","        \"\"\"\n","        Initializes a Seq2SeqModel.\n","\n","        Args:\n","            encoder_decoder_type (optional): The type of encoder-decoder model. (E.g. bart)\n","            encoder_decoder_name (optional): The path to a directory containing the saved encoder and decoder of a Seq2SeqModel. (E.g. \"outputs/\") OR a valid BART or MarianMT model.\n","            config (optional): A configuration file to build an EncoderDecoderModel.\n","            args (optional): Default args will be used if this parameter is not provided. If provided, it should be a dict containing the args that should be changed in the default args.\n","            use_cuda (optional): Use GPU if available. Setting to False will force model to use CPU only.\n","            cuda_device (optional): Specific GPU that should be used. Will use the first available GPU by default.\n","            **kwargs (optional): For providing proxies, force_download, resume_download, cache_dir and other options specific to the 'from_pretrained' implementation where this will be supplied.\n","        \"\"\"  # noqa: ignore flake8\"\n","\n","        if not config:\n","            # if not ((encoder_name and decoder_name) or encoder_decoder_name) and not encoder_type:\n","            if not encoder_decoder_name:\n","                raise ValueError(\n","                    \"You must specify a Seq2Seq config \\t OR \\t\"\n","                    \"encoder_decoder_name\"\n","                )\n","            elif not encoder_decoder_type:\n","                raise ValueError(\n","                    \"You must specify a Seq2Seq config \\t OR \\t\"\n","                    \"encoder_decoder_name\"\n","                )\n","\n","        self.args = self._load_model_args(encoder_decoder_name)\n","        print(args)\n","        if args:\n","            self.args.update_from_dict(args)\n","            print(args)\n","\n","        if self.args.manual_seed:\n","            random.seed(self.args.manual_seed)\n","            np.random.seed(self.args.manual_seed)\n","            torch.manual_seed(self.args.manual_seed)\n","            if self.args.n_gpu > 0:\n","                torch.cuda.manual_seed_all(self.args.manual_seed)\n","\n","        if use_cuda:\n","            if torch.cuda.is_available():\n","                    self.device = torch.device(\"cuda\")\n","            else:\n","                raise ValueError(\n","                    \"'use_cuda' set to True when cuda is unavailable.\"\n","                    \"Make sure CUDA is available or set `use_cuda=False`.\"\n","                )\n","        else:\n","            self.device = \"cpu\"\n","\n","        self.results = {}\n","\n","        if not use_cuda:\n","            self.args.fp16 = False\n","\n","        # config = EncoderDecoderConfig.from_encoder_decoder_configs(config, config)\n","        #if encoder_decoder_type:\n","        config_class, model_class, tokenizer_class = MODEL_CLASSES[encoder_decoder_type]\n","\n","        self.model = model_class.from_pretrained(encoder_decoder_name)\n","        self.encoder_tokenizer = tokenizer_class.from_pretrained(encoder_decoder_name)\n","        self.decoder_tokenizer = self.encoder_tokenizer\n","        self.config = self.model.config\n","\n","        if self.args.wandb_project and not wandb_available:\n","            warnings.warn(\"wandb_project specified but wandb is not available. Wandb disabled.\")\n","            self.args.wandb_project = None\n","\n","        self.args.model_name = encoder_decoder_name\n","        self.args.model_type = encoder_decoder_type\n","\n","    def train_model(\n","        self,\n","        train_data,\n","        best_accuracy,\n","        output_dir=None,\n","        show_running_loss=True,\n","        args=None,\n","        eval_data=None,\n","        test_data=None,\n","        verbose=True,\n","        **kwargs,\n","    ):\n","        \"\"\"\n","        Trains the model using 'train_data'\n","\n","        Args:\n","            train_data: Pandas DataFrame containing the 2 columns - `input_text`, `target_text`.\n","                        - `input_text`: The input text sequence.\n","                        - `target_text`: The target text sequence\n","            output_dir: The directory where model files will be saved. If not given, self.args.output_dir will be used.\n","            show_running_loss (optional): Set to False to prevent running loss from being printed to console. Defaults to True.\n","            args (optional): Optional changes to the args dict of the model. Any changes made will persist for the model.\n","            eval_data (optional): A DataFrame against which evaluation will be performed\n","            **kwargs: Additional metrics that should be used. Pass in the metrics as keyword arguments (name of metric: function to use).\n","                        A metric function should take in two parameters. The first parameter will be the true labels, and the second parameter will be the predictions. Both inputs\n","                        will be lists of strings. Note that this will slow down training significantly as the predicted sequences need to be generated.\n","\n","        Returns:\n","            None\n","        \"\"\"  # noqa: ignore flake8\"\n","\n","        if args:\n","            self.args.update_from_dict(args)\n","        #self.args = args\n","        if self.args.silent:\n","            show_running_loss = False\n","\n","\n","        if not output_dir:\n","            output_dir = self.args.output_dir\n","\n","        \"\"\"if os.path.exists(output_dir) and os.listdir(output_dir) and not self.args.overwrite_output_dir:\n","            raise ValueError(\n","                \"Output directory ({}) already exists and is not empty.\"\n","                \" Set args.overwrite_output_dir = True to overcome.\".format(output_dir)\n","            )\"\"\"\n","\n","        self._move_model_to_device()\n","\n","        train_dataset = self.load_and_cache_examples(train_data, verbose=verbose)\n","\n","        os.makedirs(output_dir, exist_ok=True)\n","\n","        global_step, tr_loss, best_accuracy = self.train(\n","            train_dataset,\n","            output_dir,\n","            best_accuracy,\n","            show_running_loss=show_running_loss,\n","            eval_data=eval_data,\n","            test_data=test_data,\n","            verbose=verbose,\n","            **kwargs,\n","        )\n","\n","        final_dir = self.args.output_dir + \"/final\"\n","        self._save_model(final_dir, model=self.model)\n","\n","        if verbose:\n","            logger.info(\" Training of {} model complete. Saved best to {}.\".format(self.args.model_name, final_dir))\n","\n","        return best_accuracy\n","\n","    def train(\n","        self, \n","        train_dataset, \n","        output_dir, \n","        best_accuracy, \n","        show_running_loss=True, \n","        eval_data=None, \n","        test_data=None,\n","        verbose=True, \n","        **kwargs,\n","    ):\n","        \"\"\"\n","        Trains the model on train_dataset.\n","\n","        Utility function to be used by the train_model() method. Not intended to be used directly.\n","        \"\"\"\n","        \n","        #epoch_lst = []\n","        #acc_detects, pre_detects, rec_detects, f1_detects, accs, pre_absas, rec_absas, f1_absas = [], [], [], [], [], [], [], []\n","        #tacc_detects, tpre_detects, trec_detects, tf1_detects, taccs, tpre_absas, trec_absas, tf1_absas = [], [], [], [], [], [], [], []\n","\n","        model = self.model\n","        args = self.args\n","\n","        tb_writer = SummaryWriter(logdir=args.tensorboard_dir)\n","        train_sampler = RandomSampler(train_dataset)\n","        train_dataloader = DataLoader(\n","            train_dataset,\n","            sampler=train_sampler,\n","            batch_size=args.train_batch_size,\n","            num_workers=self.args.dataloader_num_workers,\n","        )\n","\n","        if args.max_steps > 0:\n","            t_total = args.max_steps\n","            args.num_train_epochs = args.max_steps // (len(train_dataloader) // args.gradient_accumulation_steps) + 1\n","        else:\n","            t_total = len(train_dataloader) // args.gradient_accumulation_steps * args.num_train_epochs\n","\n","        no_decay = [\"bias\", \"LayerNorm.weight\"]\n","\n","        optimizer_grouped_parameters = []\n","        custom_parameter_names = set()\n","        for group in self.args.custom_parameter_groups:\n","            params = group.pop(\"params\")\n","            custom_parameter_names.update(params)\n","            param_group = {**group}\n","            param_group[\"params\"] = [p for n, p in model.named_parameters() if n in params]\n","            optimizer_grouped_parameters.append(param_group)\n","\n","        for group in self.args.custom_layer_parameters:\n","            layer_number = group.pop(\"layer\")\n","            layer = f\"layer.{layer_number}.\"\n","            group_d = {**group}\n","            group_nd = {**group}\n","            group_nd[\"weight_decay\"] = 0.0\n","            params_d = []\n","            params_nd = []\n","            for n, p in model.named_parameters():\n","                if n not in custom_parameter_names and layer in n:\n","                    if any(nd in n for nd in no_decay):\n","                        params_nd.append(p)\n","                    else:\n","                        params_d.append(p)\n","                    custom_parameter_names.add(n)\n","            group_d[\"params\"] = params_d\n","            group_nd[\"params\"] = params_nd\n","\n","            optimizer_grouped_parameters.append(group_d)\n","            optimizer_grouped_parameters.append(group_nd)\n","\n","        if not self.args.train_custom_parameters_only:\n","            optimizer_grouped_parameters.extend(\n","                [\n","                    {\n","                        \"params\": [\n","                            p\n","                            for n, p in model.named_parameters()\n","                            if n not in custom_parameter_names and not any(nd in n for nd in no_decay)\n","                        ],\n","                        \"weight_decay\": args.weight_decay,\n","                    },\n","                    {\n","                        \"params\": [\n","                            p\n","                            for n, p in model.named_parameters()\n","                            if n not in custom_parameter_names and any(nd in n for nd in no_decay)\n","                        ],\n","                        \"weight_decay\": 0.0,\n","                    },\n","                ]\n","            )\n","\n","        warmup_steps = math.ceil(t_total * args.warmup_ratio)\n","        args.warmup_steps = warmup_steps if args.warmup_steps == 0 else args.warmup_steps\n","\n","        # TODO: Use custom optimizer like with BertSum?\n","        optimizer = AdamW(optimizer_grouped_parameters, lr=args.learning_rate, eps=args.adam_epsilon)\n","        scheduler = get_linear_schedule_with_warmup(\n","            optimizer, num_warmup_steps=args.warmup_steps, num_training_steps=t_total\n","        )\n","\n","        if (args.model_name and os.path.isfile(os.path.join(args.model_name, \"optimizer.pt\")) and os.path.isfile(os.path.join(args.model_name, \"scheduler.pt\"))):\n","            # Load in optimizer and scheduler states\n","            optimizer.load_state_dict(torch.load(os.path.join(args.model_name, \"optimizer.pt\")))\n","            scheduler.load_state_dict(torch.load(os.path.join(args.model_name, \"scheduler.pt\")))\n","\n","        if args.n_gpu > 1:\n","            model = torch.nn.DataParallel(model)\n","\n","        logger.info(\" Training started\")\n","\n","        global_step = 0\n","        tr_loss, logging_loss = 0.0, 0.0\n","        model.zero_grad()\n","        train_iterator = trange(int(args.num_train_epochs), desc=\"Epoch\", disable=args.silent, mininterval=0)\n","        epoch_number = 0\n","        best_eval_metric = None\n","        early_stopping_counter = 0\n","        steps_trained_in_current_epoch = 0\n","        epochs_trained = 0\n","\n","        if args.model_name and os.path.exists(args.model_name):\n","            try:\n","                # set global_step to gobal_step of last saved checkpoint from model path\n","                checkpoint_suffix = args.model_name.split(\"/\")[-1].split(\"-\")\n","                if len(checkpoint_suffix) > 2:\n","                    checkpoint_suffix = checkpoint_suffix[1]\n","                else:\n","                    checkpoint_suffix = checkpoint_suffix[-1]\n","                global_step = int(checkpoint_suffix)\n","                epochs_trained = global_step // (len(train_dataloader) // args.gradient_accumulation_steps)\n","                steps_trained_in_current_epoch = global_step % (\n","                    len(train_dataloader) // args.gradient_accumulation_steps\n","                )\n","\n","                logger.info(\"   Continuing training from checkpoint, will skip to saved global_step\")\n","                logger.info(\"   Continuing training from epoch %d\", epochs_trained)\n","                logger.info(\"   Continuing training from global step %d\", global_step)\n","                logger.info(\"   Will skip the first %d steps in the current epoch\", steps_trained_in_current_epoch)\n","            except ValueError:\n","                logger.info(\"   Starting fine-tuning.\")\n","\n","        if args.wandb_project:\n","            wandb.init(project=args.wandb_project, config={**asdict(args)}, **args.wandb_kwargs)\n","            wandb.watch(self.model)\n","\n","        if args.fp16:\n","            from torch.cuda import amp\n","\n","            scaler = amp.GradScaler()\n","\n","        model.train()\n","        for current_epoch in train_iterator:\n","            if epochs_trained > 0:\n","                epochs_trained -= 1\n","                continue\n","            train_iterator.set_description(f\"Epoch {epoch_number + 1} of {args.num_train_epochs}\")\n","            batch_iterator = tqdm(\n","                train_dataloader,\n","                desc=f\"Running Epoch {epoch_number} of {args.num_train_epochs}\",\n","                disable=args.silent,\n","                mininterval=0,\n","            )\n","            for step, batch in enumerate(batch_iterator):\n","                if steps_trained_in_current_epoch > 0:\n","                    steps_trained_in_current_epoch -= 1\n","                    continue\n","                # batch = tuple(t.to(device) for t in batch)\n","\n","                inputs = self._get_inputs_dict(batch)\n","                if args.fp16:\n","                    with amp.autocast():\n","                        outputs = model(**inputs)\n","                        # model outputs are always tuple in pytorch-transformers (see doc)\n","                        loss = outputs[0]\n","                else:\n","                    outputs = model(**inputs)\n","                    # model outputs are always tuple in pytorch-transformers (see doc)\n","                    loss = outputs[0]\n","\n","                if args.n_gpu > 1:\n","                    loss = loss.mean()  # mean() to average on multi-gpu parallel training\n","\n","                current_loss = loss.item()\n","\n","                if show_running_loss:\n","                    batch_iterator.set_description(\n","                        f\"Epochs {epoch_number}/{args.num_train_epochs}. Running Loss: {current_loss:9.4f}\"\n","                    )\n","\n","                if args.gradient_accumulation_steps > 1:\n","                    loss = loss / args.gradient_accumulation_steps\n","\n","                if args.fp16:\n","                    scaler.scale(loss).backward()\n","                else:\n","                    loss.backward()\n","\n","                tr_loss += loss.item()\n","                if (step + 1) % args.gradient_accumulation_steps == 0:\n","                    if args.fp16:\n","                        scaler.unscale_(optimizer)\n","                    torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n","\n","                    if args.fp16:\n","                        scaler.step(optimizer)\n","                        scaler.update()\n","                    else:\n","                        optimizer.step()\n","                    scheduler.step()  # Update learning rate schedule\n","                    model.zero_grad()\n","                    global_step += 1\n","\n","                    if args.logging_steps > 0 and global_step % args.logging_steps == 0:\n","                        # Log metrics\n","                        tb_writer.add_scalar(\"lr\", scheduler.get_lr()[0], global_step)\n","                        tb_writer.add_scalar(\"loss\", (tr_loss - logging_loss) / args.logging_steps, global_step)\n","                        logging_loss = tr_loss\n","                        if args.wandb_project:\n","                            wandb.log(\n","                                {\n","                                    \"Training loss\": current_loss,\n","                                    \"lr\": scheduler.get_lr()[0],\n","                                    \"global_step\": global_step,\n","                                }\n","                            )\n","\n","                    if args.save_steps > 0 and global_step % args.save_steps == 0:\n","                        # Save model checkpoint\n","                        output_dir_current = os.path.join(output_dir, \"checkpoint-{}\".format(global_step))\n","\n","                        self._save_model(output_dir_current, optimizer, scheduler, model=model)\n","\n","            epoch_number += 1\n","            output_dir_current = os.path.join(output_dir, \"checkpoint-{}-epoch-{}\".format(global_step, epoch_number))\n","\n","            \n","            print('batch: '+str(args.train_batch_size)+' accumulation_steps: '+str(args.gradient_accumulation_steps)+\\\n","                ' lr: '+str(args.learning_rate)+' epochs: '+str(args.num_train_epochs)+' epoch: '+str(epoch_number))\n","            print('---dev dataset----')\n","            acc_detect, pre_detect, rec_detect, f1_detect, acc, pre_absa, rec_absa, f1_absa = predict_df(model, eval_data, tokenizer=self.encoder_tokenizer, device=self.device)\n","            print('---test dataset----')\n","            tacc_detect, tpre_detect, trec_detect, tf1_detect, tacc, tpre_absa, trec_absa, tf1_absa = predict_df(model, test_data, tokenizer=self.encoder_tokenizer, device=self.device)\n","            if acc > best_accuracy:\n","                best_accuracy = acc\n","                if not args.save_model_every_epoch:\n","                    self._save_model(output_dir_current, optimizer, scheduler, model=model)\n","                with open('./MAMS_best_accuracy.txt', 'a') as f0:\n","                    f0.writelines('batch: '+str(args.train_batch_size)+' accumulation_steps: '+str(args.gradient_accumulation_steps)+\\\n","                                  ' lr: '+str(args.learning_rate)+' epochs: '+str(args.num_train_epochs)+' epoch: '+str(epoch_number)+' val_accuracy: '+str(best_accuracy)+\\\n","                                  ' test_accuracy: '+str(tacc)+'\\n')             \n","\n","            if args.save_model_every_epoch:\n","                os.makedirs(output_dir_current, exist_ok=True)\n","                self._save_model(output_dir_current, optimizer, scheduler, model=model)\n","\n","        return global_step, tr_loss / global_step, best_accuracy    \n","\n","    def load_and_cache_examples(self, data, evaluate=False, no_cache=False, verbose=True, silent=False):\n","        \"\"\"\n","        Creates a T5Dataset from data.\n","\n","        Utility function for train() and eval() methods. Not intended to be used directly.\n","        \"\"\"\n","\n","        encoder_tokenizer = self.encoder_tokenizer\n","        decoder_tokenizer = self.decoder_tokenizer\n","        args = self.args\n","\n","        if not no_cache:\n","            no_cache = args.no_cache\n","\n","        if not no_cache:\n","            os.makedirs(self.args.cache_dir, exist_ok=True)\n","\n","        mode = \"dev\" if evaluate else \"train\"\n","\n","        if args.dataset_class:\n","            CustomDataset = args.dataset_class\n","            return CustomDataset(encoder_tokenizer, decoder_tokenizer, args, data, mode)\n","        else:\n","            return SimpleSummarizationDataset(encoder_tokenizer, self.args, data, mode)\n","\n","    def _save_model(self, output_dir=None, optimizer=None, scheduler=None, model=None, results=None):\n","        if not output_dir:\n","            output_dir = self.args.output_dir\n","        os.makedirs(output_dir, exist_ok=True)\n","\n","        logger.info(f\"Saving model into {output_dir}\")\n","\n","        if model and not self.args.no_save:\n","            # Take care of distributed/parallel training\n","            model_to_save = model.module if hasattr(model, \"module\") else model\n","            self._save_model_args(output_dir)\n","\n","            os.makedirs(os.path.join(output_dir), exist_ok=True)\n","            model_to_save.save_pretrained(output_dir)\n","            self.config.save_pretrained(output_dir)\n","            self.encoder_tokenizer.save_pretrained(output_dir)\n","\n","            torch.save(self.args, os.path.join(output_dir, \"training_args.bin\"))\n","            if optimizer and scheduler and self.args.save_optimizer_and_scheduler:\n","                torch.save(optimizer.state_dict(), os.path.join(output_dir, \"optimizer.pt\"))\n","                torch.save(scheduler.state_dict(), os.path.join(output_dir, \"scheduler.pt\"))\n","\n","        if results:\n","            output_eval_file = os.path.join(output_dir, \"eval_results.txt\")\n","            with open(output_eval_file, \"w\") as writer:\n","                for key in sorted(results.keys()):\n","                    writer.write(\"{} = {}\\n\".format(key, str(results[key])))\n","\n","    def _move_model_to_device(self):\n","        self.model.to(self.device)\n","\n","    def _get_inputs_dict(self, batch):\n","        device = self.device\n","        pad_token_id = self.encoder_tokenizer.pad_token_id\n","        source_ids, source_mask, y = batch[\"source_ids\"], batch[\"source_mask\"], batch[\"target_ids\"]\n","        y_ids = y[:, :-1].contiguous()\n","        lm_labels = y[:, 1:].clone()\n","        lm_labels[y[:, 1:] == pad_token_id] = -100\n","\n","        inputs = {\n","            \"input_ids\": source_ids.to(device),\n","            \"attention_mask\": source_mask.to(device),\n","            \"decoder_input_ids\": y_ids.to(device),\n","            \"labels\": lm_labels.to(device),\n","        }\n","        return inputs\n","\n","    def _save_model_args(self, output_dir):\n","        os.makedirs(output_dir, exist_ok=True)\n","        self.args.save(output_dir)\n","\n","    def _load_model_args(self, input_dir):\n","        args = Seq2SeqArgs()\n","        args.load(input_dir)\n","        return args\n","\n","    def get_named_parameters(self):\n","        return [n for n, p in self.model.named_parameters()]"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Training"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-21T15:45:09.556112Z","iopub.status.busy":"2023-06-21T15:45:09.555720Z","iopub.status.idle":"2023-06-21T15:45:17.952090Z","shell.execute_reply":"2023-06-21T15:45:17.951097Z","shell.execute_reply.started":"2023-06-21T15:45:09.556079Z"},"trusted":true},"outputs":[],"source":["train_df = pd.read_csv(\"datasets/preprocessed/bartpho/bartpho_res_train.csv\") #This is for ASC-only training, use bartpho_res_train_detect.csv for ACD-ASC\n","eval_df = pd.read_csv(\"datasets/preprocessed/bartpho/res_dev.csv\")\n","test_df = pd.read_csv(\"datasets/preprocessed/bartpho/res_test.csv\")\n","# steps = [1, 2, 3, 4, 6]\n","# learing_rates = [4e-5, 2e-5, 1e-5, 3e-5]\n","steps = [1]\n","learning_rates = [1e-5]\n","\n","best_accuracy = 0\n","for lr in learning_rates:\n","    for step in steps:\n","        model_args = {\n","            \"reprocess_input_data\": True,\n","            \"overwrite_output_dir\": True,\n","            \"max_seq_length\": 512,\n","            \"train_batch_size\": 10,\n","            \"num_train_epochs\": 10,\n","            \"save_model_every_epoch\": True,\n","            \"use_multiprocessing\": False,\n","            \"max_length\": 32,\n","            \"manual_seed\": 42,\n","            \"gradient_accumulation_steps\": step,\n","            \"learning_rate\":  lr,\n","            \"save_steps\": 99999999999999,\n","        }\n","\n","        # Initialize model\n","        model = Seq2SeqModel(\n","            encoder_decoder_type=\"bartpho\",\n","            encoder_decoder_name=\"vinai/bartpho-word-base\",\n","            args=model_args,\n","        )\n","\n","        #Train the model\n","        best_accuracy = model.train_model(train_data=train_df,\n","                                          best_accuracy=best_accuracy,\n","                                          eval_data=eval_df, \n","                                          test_data=test_df)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Demo & Testing"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-06-28T09:52:59.785708Z","iopub.status.busy":"2023-06-28T09:52:59.785318Z","iopub.status.idle":"2023-06-28T09:52:59.897011Z","shell.execute_reply":"2023-06-28T09:52:59.896091Z","shell.execute_reply.started":"2023-06-28T09:52:59.785676Z"},"trusted":true},"outputs":[],"source":["train_df = pd.read_csv(\"datasets/preprocessed/bartpho/res_train.csv\")\n","eval_df = pd.read_csv(\"datasets/preprocessed/bartpho/res_dev.csv\")\n","test_df = pd.read_csv(\"datasets/preprocessed/bartpho/res_test.csv\")"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-06-28T09:53:01.515677Z","iopub.status.busy":"2023-06-28T09:53:01.515271Z","iopub.status.idle":"2023-06-28T09:53:11.978154Z","shell.execute_reply":"2023-06-28T09:53:11.977073Z","shell.execute_reply.started":"2023-06-28T09:53:01.515645Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["{'max_seq_length': 512, 'max_length': 32, 'manual_seed': 42}\n","{'max_seq_length': 512, 'max_length': 32, 'manual_seed': 42}\n"]}],"source":["model_args = {\n","    \"max_seq_length\": 512,\n","    \"max_length\": 32,\n","    \"manual_seed\": 42\n","}\n","\n","model = Seq2SeqModel(\n","    encoder_decoder_type=\"bartpho\",\n","    encoder_decoder_name=\"checkpoints/bartpho/checkpoint-35540-epoch-10\", #Checkpoint for model ASC-only for ACD-ASC, use detect_checkpoint-22415-epoch-5\n","    args=model_args,\n","    )"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-06-28T09:53:13.503309Z","iopub.status.busy":"2023-06-28T09:53:13.502950Z","iopub.status.idle":"2023-06-28T09:53:15.023612Z","shell.execute_reply":"2023-06-28T09:53:15.022548Z","shell.execute_reply.started":"2023-06-28T09:53:13.503280Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7f4453ba6d344108a2b1e0481f685213","version_major":2,"version_minor":0},"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/898 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bccfd375ea74483f927b8b54344520cf","version_major":2,"version_minor":0},"text/plain":["Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/895k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8976d3e7d3b840dbb23cd941073c92ed","version_major":2,"version_minor":0},"text/plain":["Downloading (…)solve/main/bpe.codes:   0%|          | 0.00/1.14M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}],"source":["tokenizer = AutoTokenizer.from_pretrained(\"vinai/bartpho-word-base\")"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-06-28T09:53:17.190428Z","iopub.status.busy":"2023-06-28T09:53:17.189972Z","iopub.status.idle":"2023-06-28T09:53:17.196315Z","shell.execute_reply":"2023-06-28T09:53:17.195401Z","shell.execute_reply.started":"2023-06-28T09:53:17.190352Z"},"trusted":true},"outputs":[],"source":["text = \"đợt vừa_rồi gia_đình mình có qua ăn tại nhà_hàng phải nói là đồ ăn thật tươi ngon giá_cả phải_chăng đặc biết là không_gian rộng thoáng mát nhân_viên phục_vụ tận_tình chu_đáo bọn trẻ được buổi tha_hồ vui_chơi ăn_uống và còn được khám_phá thêm về thế_giới hải_sản đủ màu_sắc hình_dáng mình và gia_đình thì cùng tận_hưởng từng mùi_vị thơm ngon đặc_trưng của từng món lần sau nhất_định mình sẽ lại chọn dori\""]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2023-06-28T09:55:56.966428Z","iopub.status.busy":"2023-06-28T09:55:56.966041Z","iopub.status.idle":"2023-06-28T09:55:56.971104Z","shell.execute_reply":"2023-06-28T09:55:56.970047Z","shell.execute_reply.started":"2023-06-28T09:55:56.966392Z"},"trusted":true},"outputs":[],"source":["text1 = \"- 60k/1con- Tu hài to, siêu béo siêu ngon, nướng mỡ hành thơm phức, béo ngậy- Đĩa tu hài đem ra nóng hổi, gắp 1 miếng vào miệng kích thích vi giác kinh khủng- 1 con to đến mức họ phải cắt ra làm đôi, ăn nửa con đầy ý miệng luôn ý. Mà giá đó cho 1 con tu hài ngon như vậy là quá rẻ!\""]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2023-06-28T09:55:59.014272Z","iopub.status.busy":"2023-06-28T09:55:59.013918Z","iopub.status.idle":"2023-06-28T09:55:59.269615Z","shell.execute_reply":"2023-06-28T09:55:59.268694Z","shell.execute_reply.started":"2023-06-28T09:55:59.014240Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["{'FOOD#PRICES': 'positive', 'FOOD#QUALITY': 'positive', 'FOOD#STYLE&OPTIONS': 'positive'}\n"]},{"data":{"text/plain":["[0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0]"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["predict(model.model, text1, tokenizer, model_tokenize, processed=False, printout=True) #this is for ASC-only predict, use predict_detect for ACD-ASC"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2023-06-28T09:56:43.022473Z","iopub.status.busy":"2023-06-28T09:56:43.022067Z","iopub.status.idle":"2023-06-28T09:59:38.541080Z","shell.execute_reply":"2023-06-28T09:59:38.540115Z","shell.execute_reply.started":"2023-06-28T09:56:43.022440Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Detect acc: 86.4167%\n","Detect precision: 84.3874%\n","Detect recall: 82.8573%\n","Detect f1: 82.2991%\n","\n","Absa acc: 81.7000%\n","Absa precision: 72.4274%\n","Absa recall: 70.9936%\n","Absa f1: 70.5499%\n"]},{"data":{"text/plain":["(0.8641666666666666,\n"," 0.84387380952381,\n"," 0.8285726551226559,\n"," 0.8229912055265017,\n"," 0.817,\n"," 0.72427380952381,\n"," 0.709936075036076,\n"," 0.7054994175758901)"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["predict_df(model.model, test_df, tokenizer, model_tokenize) #this is for ASC-only predict, use predict_df_detect for ACD-ASC"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"}},"nbformat":4,"nbformat_minor":4}
