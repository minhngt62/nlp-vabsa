{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pyvi","metadata":{"id":"QKAo49Dm-sLP","execution":{"iopub.status.busy":"2023-06-26T10:03:38.820876Z","iopub.execute_input":"2023-06-26T10:03:38.821723Z","iopub.status.idle":"2023-06-26T10:03:52.250447Z","shell.execute_reply.started":"2023-06-26T10:03:38.821680Z","shell.execute_reply":"2023-06-26T10:03:52.249024Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting pyvi\n  Downloading pyvi-0.1.1-py2.py3-none-any.whl (8.5 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from pyvi) (1.2.2)\nCollecting sklearn-crfsuite (from pyvi)\n  Downloading sklearn_crfsuite-0.3.6-py2.py3-none-any.whl (12 kB)\nRequirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->pyvi) (1.23.5)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->pyvi) (1.10.1)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->pyvi) (1.2.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->pyvi) (3.1.0)\nCollecting python-crfsuite>=0.8.3 (from sklearn-crfsuite->pyvi)\n  Downloading python_crfsuite-0.9.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (993 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m993.5/993.5 kB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from sklearn-crfsuite->pyvi) (1.16.0)\nRequirement already satisfied: tabulate in /opt/conda/lib/python3.10/site-packages (from sklearn-crfsuite->pyvi) (0.9.0)\nRequirement already satisfied: tqdm>=2.0 in /opt/conda/lib/python3.10/site-packages (from sklearn-crfsuite->pyvi) (4.64.1)\nInstalling collected packages: python-crfsuite, sklearn-crfsuite, pyvi\nSuccessfully installed python-crfsuite-0.9.9 pyvi-0.1.1 sklearn-crfsuite-0.3.6\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport re\nimport json\nimport string\nimport emoji\nimport pandas as pd\nfrom preprocess import normalize, tokenize\nfrom utils import tag_dict, polarity_dict, polarity_list, tags, eng_tags, eng_polarity, detect_labels, no_polarity, no_tag\nfrom utils import predict, predict_df\nfrom pyvi.ViTokenizer import tokenize as model_tokenize","metadata":{"execution":{"iopub.status.busy":"2023-06-26T10:03:52.252592Z","iopub.execute_input":"2023-06-26T10:03:52.252954Z","iopub.status.idle":"2023-06-26T10:03:52.942669Z","shell.execute_reply.started":"2023-06-26T10:03:52.252918Z","shell.execute_reply":"2023-06-26T10:03:52.941514Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"data=open(r'/kaggle/input/vlsp2018absa/VLSP2018-SA-Restaurant-train.txt').read()\n\nopinions = data.split('\\n\\n')\n    \nsentences, tags_lst, sentiments_lst, lengths = [], [], [], []\n#count = 0\nfor i in opinions:\n    #count += 1\n    splitt = i.split(\"\\n\")\n    num, sentence, aspects = splitt[0], splitt[1], splitt[2]\n    sentence = normalize(sentence)\n    sentence = tokenize(sentence, model_tokenize)\n    aspects = split_aspect(aspects)\n    text_tags = [x[0] for x in aspects]\n    sentiments = [x[1] for x in aspects]\n    sentences.append(sentence)\n    tags_lst.append(text_tags)\n    sentiments_lst.append(sentiments)\n    lengths.append(len(sentence.split()))\n\nno_sentences = len(sentences) \nprint(no_sentences)\nprint(max(lengths))\nprint(sum(lengths)/no_sentences)\n\n'''short_ids = [i for i in range(no_sentences) if lengths[i] <= 128]\n\nfor i in range(no_sentences):\n    if i not in short_ids:\n        continue\n    else:\n        short_ids.remove(i)\n        for j in range(no_sentences):\n            if j in short_ids:\n                cmm = [x for x in tags_lst[i] if x in tags_lst[j]]\n                if len(cmm) == 0:\n                    sentences.append(sentences[i] + \" \" + sentences[j])\n                    tags_lst.append(tags_lst[i] + tags_lst[j])\n                    sentiments_lst.append(sentiments_lst[i] + sentiments_lst[j])\n                    lengths.append(lengths[i] + lengths[j])\n                    short_ids.remove(j)\n                    continue'''\n                    \nsentence_lst, targets= [], []\nfor i in range(len(sentences)):\n    for tag in tag_dict:\n        sentence = sentences[i] \n        if tag not in tags_lst[i]:\n            sentiment = polarity_dict['không có']\n            target = \"Nhận_xét \" + tag_dict[tag] + \" \" + sentiment + \" .\"\n            \n        else:\n            idx = tags_lst[i].index(tag)\n            target = \"Nhận_xét \" + tag_dict[tag] + \" \" + polarity_dict[sentiments_lst[i][idx]]+ \" .\"\n        sentence_lst.append(sentence)\n        targets.append(target)\n        \ndf = pd.DataFrame()\ndf['input_text'] = sentence_lst\ndf['target_text'] = targets\ndf.to_csv(\"bartpho_res_train.csv\", index = False)","metadata":{"execution":{"iopub.status.busy":"2023-06-26T10:06:15.188188Z","iopub.execute_input":"2023-06-26T10:06:15.188632Z","iopub.status.idle":"2023-06-26T10:07:34.912280Z","shell.execute_reply.started":"2023-06-26T10:06:15.188601Z","shell.execute_reply":"2023-06-26T10:07:34.910907Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"2961\n615\n58.211077338736914\n","output_type":"stream"}]},{"cell_type":"code","source":"data=open(r'/kaggle/input/vlsp2018absa/VLSP2018-SA-Restaurant-train.txt').read()\n\nopinions = data.split('\\n\\n')\n    \nsentences, tags_lst, sentiments_lst, lengths = [], [], [], []\n#count = 0\nfor i in opinions:\n    #count += 1\n    splitt = i.split(\"\\n\")\n    num, sentence, aspects = splitt[0], splitt[1], splitt[2]\n    sentence = normalize(sentence)\n    sentence = tokenize(sentence, model_tokenize)\n    aspects = split_aspect(aspects)\n    text_tags = [x[0] for x in aspects]\n    sentiments = [x[1] for x in aspects]\n    sentences.append(sentence)\n    tags_lst.append(text_tags)\n    sentiments_lst.append(sentiments)\n    lengths.append(len(sentence.split()))\n\nno_sentences = len(sentences) \nprint(no_sentences)\nprint(max(lengths))\nprint(sum(lengths)/no_sentences)\n\n'''short_ids = [i for i in range(no_sentences) if lengths[i] <= 128]\n\nfor i in range(no_sentences):\n    if i not in short_ids:\n        continue\n    else:\n        short_ids.remove(i)\n        for j in range(no_sentences):\n            if j in short_ids:\n                cmm = [x for x in tags_lst[i] if x in tags_lst[j]]\n                if len(cmm) == 0:\n                    sentences.append(sentences[i] + \" \" + sentences[j])\n                    tags_lst.append(tags_lst[i] + tags_lst[j])\n                    sentiments_lst.append(sentiments_lst[i] + sentiments_lst[j])\n                    lengths.append(lengths[i] + lengths[j])\n                    short_ids.remove(j)\n                    continue'''\n                    \nsentence_lst, targets= [], []\nfor i in range(len(sentences)):\n    for tag in tag_dict:\n        sentence = sentences[i] \n        if tag not in tags_lst[i]:\n            detect_target = tag_dict[tag] + \" không được nhận_xét .\"\n            #sentiment = polarity_dict['không có']\n            #target = \"Nhận_xét \" + tag_dict[tag] + \" \" + sentiment + \" .\"\n            \n        else:\n            idx = tags_lst[i].index(tag)\n            absa_target = \"Nhận_xét \" + tag_dict[tag] + \" \" + polarity_dict[sentiments_lst[i][idx]]+ \" .\"\n            sentence_lst.append(sentence)\n            targets.append(absa_target)\n            detect_target = tag_dict[tag] + \" có được nhận_xét .\"\n        sentence_lst.append(sentence)\n        targets.append(detect_target)\n        \ndf = pd.DataFrame()\ndf['input_text'] = sentence_lst\ndf['target_text'] = targets\ndf.to_csv(\"bartpho_res_train_detect.csv\", index = False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data=open(r'/kaggle/input/vlsp2018absa/VLSP2018-SA-Restaurant-train.txt').read()\nopinions = data.split('\\n\\n')\nsentences = []\naspect_cols = [[] for i in range(len(tags))]\n\nfor i in opinions:\n    splitt = i.split(\"\\n\")\n    num, sentence, aspects = splitt[0], splitt[1], splitt[2]\n    sentence = normalize(sentence)\n    sentence = tokenize(sentence, model_tokenize)\n    aspects = split_aspect(aspects)\n    text_tags = [x[0] for x in aspects]\n    sentiments = [x[1] for x in aspects]\n    sentences.append(sentence)\n    for j in range(len(tags)):\n        tag = eng_tags[j]\n        if tag not in text_tags:\n            aspect_cols[j].append(0) \n        else:\n            idx = text_tags.index(tag)\n            aspect_cols[j].append(eng_polarity.index(sentiments[idx]))\n\ndf = pd.DataFrame()\ndf['text'] = sentences\nfor i in range(len(tags)):\n    df[eng_tags[i]] = aspect_cols[i]\ndf.to_csv(\"res_train.csv\", index = False)\nwith open('sentences.json', 'w') as f:\n    json.dump(sentences, f, ensure_ascii=False, indent=4)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}