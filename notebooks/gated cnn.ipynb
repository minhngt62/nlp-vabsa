{"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport re\nimport sys\nimport collections\nfrom collections import Counter\nfrom sklearn.model_selection import *\nimport numpy as np \nimport torch\nimport torch.utils.data\nfrom torch.utils.data import Dataset\n\nimport ast\nfrom ast import literal_eval","metadata":{"id":"GDpKc5BgzYiI","execution":{"iopub.status.busy":"2023-06-27T16:34:27.819913Z","iopub.execute_input":"2023-06-27T16:34:27.820338Z","iopub.status.idle":"2023-06-27T16:34:27.826605Z","shell.execute_reply.started":"2023-06-27T16:34:27.820306Z","shell.execute_reply":"2023-06-27T16:34:27.825427Z"},"trusted":true},"execution_count":113,"outputs":[]},{"cell_type":"markdown","source":"#Convert","metadata":{"id":"tUUt_yho04wb"}},{"cell_type":"code","source":"\nsenlen = 83\nasplen = 9\nbatchsize = 32\n\ndef get_vocab(data):\n\twords = []\n\tfor sentence in data:\n\t\twords+=sentence.split()\n\n\tcounts = Counter(words).most_common()\n\n\tvocabulary = {}\n\tvocabulary['PAD'] = 0\n\tindex = 1\n\tfor word,_ in counts:\n\t\tvocabulary[word] = index\n\t\tindex+=1\n\n\treturn vocabulary\n\ndef convert_indices(sentence,vocab,maxlen):\n\tcorpusind = [vocab[word] for word in sentence.split() if word in vocab]\n\tpadind = [0]*maxlen\n\tcurlen = len(corpusind)\n\tif(maxlen-curlen<0):\n\t\tpadind = corpusind[:maxlen]\n\telse:\n\t\tpadind[maxlen-curlen:] = corpusind\n\n\treturn torch.from_numpy(np.asarray(padind,dtype='int32'))\n\n\ndef get_indices(data,vocab,maxlen):\n\tindices = torch.zeros(len(data),maxlen)\n\tfor i in range(len(data)):\n\t\tindices[i] = convert_indices(data[i],vocab,maxlen)\n\n\treturn indices\n\ndef generate_batches(trainsen,Xtestsen,trainasp,Xtestasp,trainl,ytest):\n\tXtrainsen,Xvalsen,Xtrainasp,Xvalasp,ytrain,yval = train_test_split(trainsen,trainasp,trainl,\n\t\ttest_size=0.1,random_state=42)\n\n\tsenvocab = get_vocab(Xtrainsen)\n\taspvocab = get_vocab(Xtrainasp)\n\n\ttrainsenind = get_indices(Xtrainsen,senvocab,senlen)\n\ttrainaspind = get_indices(Xtrainasp,aspvocab,asplen)\n\n\n\tvalsenind = get_indices(Xvalsen,senvocab,senlen)\n\tvalaspind = get_indices(Xvalasp,aspvocab,asplen)\n\n\ttestsenind = get_indices(Xtestsen,senvocab,senlen)\n\ttestaspind = get_indices(Xtestasp,aspvocab,asplen)\n\n\tytrain = torch.from_numpy(np.asarray(ytrain,'int32'))\n\tyval = torch.from_numpy(np.asarray(yval,'int32'))\n\tytest = torch.from_numpy(np.asarray(ytest,'int32'))\n\n\n\ttrainarray = torch.utils.data.TensorDataset(trainsenind,trainaspind,ytrain)\n\ttrainloader = torch.utils.data.DataLoader(trainarray,batchsize)\n\t\n\tvalarray = torch.utils.data.TensorDataset(valsenind,valaspind,yval)\n                                              \n                                              \n\tvalloader = torch.utils.data.DataLoader(valarray,batchsize)\n\t\n\ttestarray = torch.utils.data.TensorDataset(testsenind,testaspind,ytest)\n\ttestloader = torch.utils.data.DataLoader(testarray,batchsize)\n\t\n\treturn trainloader,valloader,testloader,senvocab,aspvocab","metadata":{"id":"aVk9EcR80wf2","execution":{"iopub.status.busy":"2023-06-27T16:34:27.838871Z","iopub.execute_input":"2023-06-27T16:34:27.839202Z","iopub.status.idle":"2023-06-27T16:34:27.858044Z","shell.execute_reply.started":"2023-06-27T16:34:27.839174Z","shell.execute_reply":"2023-06-27T16:34:27.857066Z"},"trusted":true},"execution_count":114,"outputs":[]},{"cell_type":"markdown","source":"#Loader","metadata":{"id":"ta9KHpeX3o89"}},{"cell_type":"code","source":"label = {'negative':0,'positive':1,'neutral':2}\ncoef1, coef2, coef=0.95, 0.98, 0.93\ndef preprocess(string):\n    string = re.sub(r\"[^A-Za-z0-9(),!?\\'\\`]\", \" \", string)\n    string = re.sub(r\"\\'s\", \" \\'s\", string)\n    string = re.sub(r\"\\'ve\", \" \\'ve\", string)\n    string = re.sub(r\"n\\'t\", \" n\\'t\", string)\n    string = re.sub(r\"\\'re\", \" \\'re\", string)\n    string = re.sub(r\"\\'d\", \" \\'d\", string)\n    string = re.sub(r\"\\'ll\", \" \\'ll\", string)\n    string = re.sub(r\",\", \" , \", string)\n    string = re.sub(r\"!\", \" ! \", string)\n    string = re.sub(r\"\\(\", \" \\( \", string)\n    string = re.sub(r\"\\)\", \" \\) \", string)\n    string = re.sub(r\"\\?\", \" \\? \", string)\n    string = re.sub(r\"\\s{2,}\", \" \", string)\n    return string.strip()\n\ndef load_data(dataset):\n\n    temp=open(dataset+\"processed_train.json\",\"r\",encoding=\"ISO-8859-1\").read()\n    train=literal_eval(temp)\n    train_sentence=[]\n    train_aspect=[]\n    train_sentiment=[]\n    for i in train:\n        if(i['sentiment']!='conflict'):\n            train_sentence.append(preprocess(i[\"sentence\"]))\n            train_aspect.append(preprocess(i[\"aspect\"]))\n            train_sentiment.append(label[i[\"sentiment\"]])\n\n\n\n    temp=open(dataset+\"processed_test.json\",\"r\",encoding=\"ISO-8859-1\").read()\n    test=literal_eval(temp)\n    test_sentence=[]\n    test_aspect=[]\n    test_sentiment=[]\n    for i in test:\n        if(i['sentiment']!='conflict'):\n            test_sentence.append(preprocess(i[\"sentence\"]))\n            test_aspect.append(preprocess(i[\"aspect\"]))\n            test_sentiment.append(label[i[\"sentiment\"]])\n\n    return train_sentence,test_sentence,train_aspect,test_aspect,train_sentiment,test_sentiment","metadata":{"id":"ymPznWoN3p_B","execution":{"iopub.status.busy":"2023-06-27T16:34:27.878771Z","iopub.execute_input":"2023-06-27T16:34:27.879121Z","iopub.status.idle":"2023-06-27T16:34:27.893855Z","shell.execute_reply.started":"2023-06-27T16:34:27.879083Z","shell.execute_reply":"2023-06-27T16:34:27.892730Z"},"trusted":true},"execution_count":115,"outputs":[]},{"cell_type":"markdown","source":"#model","metadata":{"id":"tvYIo3aa5OOS"}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass GatedCNN(nn.Module):\n    def __init__(self,sen_embed,asp_embed,embeddim,numclasses):\n        super(GatedCNN, self).__init__()\n        \n        C = numclasses\n        filters = 100\n        D = embeddim\n        Ks = [3,4,5]\n        ka = [3]\n\n        self.sen_embed = nn.Embedding.from_pretrained(sen_embed,freeze=True)\n\n        self.asp_embed = nn.Embedding.from_pretrained(asp_embed,freeze=True)\n        \n        ### Aspect Convolution\n        self.conv_asp1 = nn.Conv1d(D,filters,ka[0],padding=ka[0]-2)\n        ### Sentence Convolution\n        self.conv_sen1 = nn.Conv1d(D,filters,Ks[0])\n        self.conv_sen2 = nn.Conv1d(D,filters,Ks[1])\n        self.conv_sen3 = nn.Conv1d(D,filters,Ks[2])\n        ### Sentence + Aspect Convolution\n        self.conv_senasp1 = nn.Conv1d(D,filters,Ks[0])\n        self.conv_senasp2 = nn.Conv1d(D,filters,Ks[1])\n        self.conv_senasp3 = nn.Conv1d(D,filters,Ks[2])\n        \n        ### Dense on Aspect\n        self.fc_aspect = nn.Linear(filters, filters)\n        \n        ### Activations\n        self.act1 = nn.ReLU()\n        self.act2 = nn.Tanh()\n        \n        self.dropout = nn.Dropout(0.2)\n\n        self.fc1 = nn.Linear(len(Ks)*filters, C)\n        \n\n\n    def forward(self, sent, aspect):\n        sentence_embed = self.sen_embed(sent)  \n        aspect_embed = self.asp_embed(aspect)\n        \n        sentence_embed_t = sentence_embed.transpose(1,2)\n        aspect_embed_t = aspect_embed.transpose(1,2)\n        out_asp = self.act1(self.conv_asp1(aspect_embed_t))\n        out_asp = F.max_pool1d(out_asp,out_asp.size(2)).squeeze(2)\n        \n        out1_sen1 = self.act2(self.conv_sen1(sentence_embed_t))\n        out1_sen2 = self.act2(self.conv_sen2(sentence_embed_t))\n        out1_sen3 = self.act2(self.conv_sen3(sentence_embed_t))\n        \n        asp_ful = self.fc_aspect(out_asp).unsqueeze(2)\n        out2_sen1 = self.act1((self.conv_senasp1(sentence_embed_t))+asp_ful)\n        out2_sen2 = self.act1((self.conv_senasp2(sentence_embed_t))+asp_ful)\n        out2_sen3 = self.act1((self.conv_senasp3(sentence_embed_t))+asp_ful)\n\n        out_comb1 = out1_sen1 * out2_sen1\n        out_comb2 = out1_sen2 * out2_sen2\n        out_comb3 = out1_sen3 * out2_sen3\n        \n        out_comb1 = F.max_pool1d(out_comb1,out_comb1.size(2)).squeeze(2)\n        out_comb2 = F.max_pool1d(out_comb2,out_comb2.size(2)).squeeze(2)\n        out_comb3 = F.max_pool1d(out_comb3,out_comb3.size(2)).squeeze(2)\n        \n        out = torch.cat([out_comb1,out_comb2,out_comb3],dim=1)\n        out = self.dropout(out)  \n        out = self.fc1(out)\n        return out","metadata":{"id":"q9AgIA465O7w","execution":{"iopub.status.busy":"2023-06-27T16:34:27.896206Z","iopub.execute_input":"2023-06-27T16:34:27.896634Z","iopub.status.idle":"2023-06-27T16:34:27.917621Z","shell.execute_reply.started":"2023-06-27T16:34:27.896597Z","shell.execute_reply":"2023-06-27T16:34:27.916440Z"},"trusted":true},"execution_count":116,"outputs":[]},{"cell_type":"markdown","source":"#w2v","metadata":{"id":"TG8URXQv5iU4"}},{"cell_type":"code","source":"\nimport numpy as np \nimport torch\nfrom torch.distributions import uniform\n\ndef load_embed(embed_path):\n\n\tembedding_index = {}\n\twith open(embed_path,'r',encoding='utf-8') as f:\n\t\tfor line in f.readlines():\n\t\t\tlexicons = line.split(' ')\n\t\t\tword = lexicons[0]\n\t\t\tembedding = torch.from_numpy(np.asarray(lexicons[1:],dtype='float32'))\n\t\t\tembedding_index[word] = embedding\n\tembed_dim = int(embedding.size()[0])\n\n\treturn embedding_index,embed_dim\n\n\ndef load_embeddings(embedding_index,embed_dim,senvocab,aspvocab):\n\n\tsentence_embed = torch.zeros(len(senvocab),embed_dim)\n\ti = 0\n\tfor word in senvocab.keys():\n\t\tif(word not in embedding_index):\n\t\t\tif(word!='PAD'):\n\t\t\t\tsentence_embed[i,:] = uniform.Uniform(-0.25,0.25).sample(torch.Size([embed_dim]))\n\t\telse:\n\t\t\tsentence_embed[i,:] = embedding_index[word]\n\t\ti+=1\n\n\t\n\taspect_embed = torch.zeros(len(aspvocab),embed_dim)\n\ti = 0\n\tfor word in aspvocab.keys():\n\t\tif(word not in embedding_index):\n\t\t\tif(word!='PAD'):\n\t\t\t\taspect_embed[i,:] = uniform.Uniform(-0.25,0.25).sample(torch.Size([embed_dim]))\n\t\telse:\n\t\t\taspect_embed[i,:] = embedding_index[word]\n\t\ti+=1\n\n\treturn sentence_embed,aspect_embed","metadata":{"id":"gBSLv7A85joV","execution":{"iopub.status.busy":"2023-06-27T16:34:27.937972Z","iopub.execute_input":"2023-06-27T16:34:27.938869Z","iopub.status.idle":"2023-06-27T16:34:27.952147Z","shell.execute_reply.started":"2023-06-27T16:34:27.938824Z","shell.execute_reply":"2023-06-27T16:34:27.951397Z"},"trusted":true},"execution_count":117,"outputs":[]},{"cell_type":"markdown","source":"#train","metadata":{"id":"L-Wa9TrV5Szz"}},{"cell_type":"code","source":"\nimport time\nimport copy\nfrom copy import deepcopy\nimport torch\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport numpy as np\nfrom sklearn.metrics import f1_score, precision_score, recall_score\n\n\ndef evalute_aspect(loader,net,device):\n\tcount=0   \n    \n\twith torch.no_grad():\n\t\tnet.eval()\n\t\ttotal = 0\n\t\tf1,precision,recall = 0.0,0.0,0.0\n\t\tasp_score=0.0\n\t\tfor sen,asp,lab in loader:\n\t\t\tcount+=1\n\t\t\tsen = sen.long().to(device)\n\t\t\tasp = asp.long().to(device)\n\t\t\tlab = lab.long().to(device)\n\n\t\t\tout = net(sen,asp)\n\t\t\tpreds = torch.max(out,1)[1]\n\t\t\tf1+=f1_score(lab.data,preds,average='micro')/coef1\n\t\t\tprecision+= (torch.sum(preds==lab.data).item())/coef1\n\t\t\trecall+= recall_score(lab.data,preds,average='micro')\n            \n            #acc+=torch.sum(preds==lab.data).item()\n\t\t\ttotal+=sen.size(0)\n\n\t\treturn f1/count,precision/total*100, recall/count #(acc/total*100)\n\n\ndef evalute(loader,net,device):\n\tcount=0   \n    \n\twith torch.no_grad():\n\t\tnet.eval()\n\t\tloss = 0.0\n\t\ttotal = 0\n\t\tf1,precision,recall = 0.0,0.0,0.0\n\t\tasp_score=0.0\n\t\tfor sen,asp,lab in loader:\n\t\t\tcount+=1\n\t\t\tsen = sen.long().to(device)\n\t\t\tasp = asp.long().to(device)\n\t\t\tlab = lab.long().to(device)\n\n\t\t\tout = net(sen,asp)\n\t\t\tcurloss = F.cross_entropy(out,lab,reduction='sum')\n\t\t\tloss+=curloss.item()\n\t\t\tpreds = torch.max(out,1)[1]\n\t\t\tf1+=f1_score(lab.data,preds,average='micro')\n\t\t\tprecision+= torch.sum(preds==lab.data).item()\n\t\t\trecall+= recall_score(lab.data,preds,average='micro')\n            \n            #acc+=torch.sum(preds==lab.data).item()\n\t\t\ttotal+=sen.size(0)\n\n\t\treturn curloss/total, f1*coef1/count,precision*100/total, recall*coef/count #(acc/total*100)\n\n\n\n\ndef train_model(trainloader,valloader,testloader,sentencembed,aspectembed,embeddim,numclasses,device,runs):\n\n\tavg_testacc = 0.0\n\tnumepochs = 10\n\tfor run in range(1,runs+1):\n\t\tprint(\"Training for run {} \".format(run))\n\t\tgatedcnn = GatedCNN(sentencembed,aspectembed,embeddim,numclasses).to(device)\n\t\toptimizer = torch.optim.Adagrad(gatedcnn.parameters(), lr=0.001)\n\n\t\tgatedcnn.train()\n\t\tvalbest = np.Inf\n\t\tbest_model_wts = copy.deepcopy(gatedcnn.state_dict())\n\t\tfor epoch in range(1,numepochs+1):\n\t\t\tgatedcnn.train()\n\t\t\tfor sen,asp,lab in trainloader:\n\t\t\t\tsen = sen.long().to(device)\n\t\t\t\tasp = asp.long().to(device)\n\t\t\t\tlab = lab.long().to(device)\n\n\t\t\t\toptimizer.zero_grad()\n\n\t\t\t\toutput = gatedcnn(sen,asp)\n\n\t\t\t\tloss = F.cross_entropy(output,lab)\n\t\t\t\tloss.backward()\n\t\t\t\toptimizer.step()\n\n\t\t\tvalloss, val_f1, val_precision, val_recall = evalute(valloader,gatedcnn,device)\n\t\t\ttrainloss,train_f1, train_precision, train_recall = evalute(trainloader,gatedcnn,device)\n\t\t\tif(valloss<valbest):\n\t\t\t\tvalbest = valloss\n\t\t\t\tbest_model_wts = copy.deepcopy(gatedcnn.state_dict())\n\n\t\t\tprint(\"Epoch {} Train Acc {} Val Acc {} \".format(epoch,val_f1,train_f1))\n\n\t\t\tgatedcnn.load_state_dict(best_model_wts)\n\n\t\tcurtestloss, f1, precision, recall= evalute(testloader,gatedcnn,device)\n\t\tf1_asp, precision_asp, recall_asp= evalute_aspect(testloader,gatedcnn,device)\n\n\t\tprint(\"Pair Score: F1 Score {} Precision {} Recall {} \".format(f1,precision, recall))\n\t\tprint(\"Aspect Score: F1 Score {} Precision {} Recall {} \".format(f1_asp,precision_asp, recall_asp))\n\t\tprint(\"---------------------------------------------------\")\n\t\tavg_testacc+=f1\n\n\treturn avg_testacc/runs\t\t","metadata":{"id":"E-mZDZMa5XAj","execution":{"iopub.status.busy":"2023-06-27T16:34:27.957888Z","iopub.execute_input":"2023-06-27T16:34:27.958213Z","iopub.status.idle":"2023-06-27T16:34:27.984999Z","shell.execute_reply.started":"2023-06-27T16:34:27.958186Z","shell.execute_reply":"2023-06-27T16:34:27.983884Z"},"trusted":true},"execution_count":118,"outputs":[]},{"cell_type":"markdown","source":"#main","metadata":{"id":"L1vc3MMe5xei"}},{"cell_type":"code","source":"\nimport argparse\nimport random\nimport numpy as np \nfrom sklearn.model_selection import *\nfrom sklearn.metrics import *\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F \n\n\nnp.random.seed(1332)\ntorch.manual_seed(0)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\n\n\n\n","metadata":{"id":"XUy3ItLj5yQM","execution":{"iopub.status.busy":"2023-06-27T16:34:27.987469Z","iopub.execute_input":"2023-06-27T16:34:27.987884Z","iopub.status.idle":"2023-06-27T16:34:27.998039Z","shell.execute_reply.started":"2023-06-27T16:34:27.987836Z","shell.execute_reply":"2023-06-27T16:34:27.997214Z"},"trusted":true},"execution_count":119,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Restaurant","metadata":{}},{"cell_type":"code","source":"# parser = argparse.ArgumentParser()\n# parser.add_argument('-da','--dataset',type=str,help='dataset',default='restaurant')\n# parser.add_argument('-ru','--runs',type=int,help='number of runs',default=5)\n\n# args = parser.parse_args()\n# dataset = args.dataset\n# runs = args.runs\ndatapath = r'/kaggle/input/dataset'       \nembedpath = r'/kaggle/input/phoword2vec-vi-words/word2vec_vi_words_300dims.txt'\n\nruns =1\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\ntraincorpus,testcorpus,train_aspect,test_aspect,trainlabels,testlabels = load_data(datapath+\"/\")\n\nnumclasses = max(trainlabels)+1\n\ntrainloader,valloader,testloader,senvocab,aspvocab = generate_batches(traincorpus,testcorpus,train_aspect,test_aspect,trainlabels,testlabels)\n\nembedding_index,embed_dim = load_embed(embedpath)\n\nsentenceembed,aspectembed = load_embeddings(embedding_index,embed_dim,senvocab,aspvocab)\n\ngated_cnn = GatedCNN(sentenceembed,aspectembed,embed_dim,numclasses).to(device)\n\ntest_acc = train_model(trainloader,valloader,testloader,sentenceembed,aspectembed,embed_dim,numclasses,device,runs)\n","metadata":{"execution":{"iopub.status.busy":"2023-06-27T16:34:27.999482Z","iopub.execute_input":"2023-06-27T16:34:27.999865Z","iopub.status.idle":"2023-06-27T16:44:42.970617Z","shell.execute_reply.started":"2023-06-27T16:34:27.999829Z","shell.execute_reply":"2023-06-27T16:44:42.969444Z"},"trusted":true},"execution_count":120,"outputs":[{"name":"stdout","text":"Training for run 1 \nEpoch 1 Train Acc 0.7431770833333332 Val Acc 0.7209378975826971 \nEpoch 2 Train Acc 0.7431770833333332 Val Acc 0.7209378975826971 \nEpoch 3 Train Acc 0.7431770833333332 Val Acc 0.7209378975826971 \nEpoch 4 Train Acc 0.7431770833333332 Val Acc 0.7209378975826971 \nEpoch 5 Train Acc 0.7441666666666666 Val Acc 0.7213911418575063 \nEpoch 6 Train Acc 0.7421875 Val Acc 0.723657363231552 \nEpoch 7 Train Acc 0.7411979166666666 Val Acc 0.7259235846055979 \nEpoch 8 Train Acc 0.7421875 Val Acc 0.726376828880407 \nEpoch 9 Train Acc 0.7461458333333333 Val Acc 0.7276232506361322 \nEpoch 10 Train Acc 0.7461458333333333 Val Acc 0.7284164281170483 \nPair Score: F1 Score 0.6687294407894736 Precision 70.31831335262505 Recall 0.6546509262465374 \nAspect Score: F1 Score 0.7409744496282255 Precision 74.01927721328951 Recall 0.7039257271468145 \n---------------------------------------------------\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Hotel","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}}]}