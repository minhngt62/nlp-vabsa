{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-06-26T10:03:38.821723Z","iopub.status.busy":"2023-06-26T10:03:38.820876Z","iopub.status.idle":"2023-06-26T10:03:52.250447Z","shell.execute_reply":"2023-06-26T10:03:52.249024Z","shell.execute_reply.started":"2023-06-26T10:03:38.821680Z"},"id":"QKAo49Dm-sLP","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting pyvi\n","  Downloading pyvi-0.1.1-py2.py3-none-any.whl (8.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from pyvi) (1.2.2)\n","Collecting sklearn-crfsuite (from pyvi)\n","  Downloading sklearn_crfsuite-0.3.6-py2.py3-none-any.whl (12 kB)\n","Requirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->pyvi) (1.23.5)\n","Requirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->pyvi) (1.10.1)\n","Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->pyvi) (1.2.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->pyvi) (3.1.0)\n","Collecting python-crfsuite>=0.8.3 (from sklearn-crfsuite->pyvi)\n","  Downloading python_crfsuite-0.9.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (993 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m993.5/993.5 kB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from sklearn-crfsuite->pyvi) (1.16.0)\n","Requirement already satisfied: tabulate in /opt/conda/lib/python3.10/site-packages (from sklearn-crfsuite->pyvi) (0.9.0)\n","Requirement already satisfied: tqdm>=2.0 in /opt/conda/lib/python3.10/site-packages (from sklearn-crfsuite->pyvi) (4.64.1)\n","Installing collected packages: python-crfsuite, sklearn-crfsuite, pyvi\n","Successfully installed python-crfsuite-0.9.9 pyvi-0.1.1 sklearn-crfsuite-0.3.6\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["!pip install pyvi"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-06-26T10:03:52.252954Z","iopub.status.busy":"2023-06-26T10:03:52.252592Z","iopub.status.idle":"2023-06-26T10:03:52.942669Z","shell.execute_reply":"2023-06-26T10:03:52.941514Z","shell.execute_reply.started":"2023-06-26T10:03:52.252918Z"},"trusted":true},"outputs":[],"source":["import os\n","import re\n","import json\n","import string\n","import emoji\n","import pandas as pd\n","from vabsa.bartpho.preprocess import normalize, tokenize\n","from vabsa.bartpho.utils import tag_dict, polarity_dict, polarity_list, tags, eng_tags, eng_polarity, detect_labels, no_polarity, no_tag\n","from vabsa.bartpho.utils import predict, predict_df\n","from pyvi.ViTokenizer import tokenize as model_tokenize"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-06-26T10:06:15.188632Z","iopub.status.busy":"2023-06-26T10:06:15.188188Z","iopub.status.idle":"2023-06-26T10:07:34.912280Z","shell.execute_reply":"2023-06-26T10:07:34.910907Z","shell.execute_reply.started":"2023-06-26T10:06:15.188601Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["2961\n","615\n","58.211077338736914\n"]}],"source":["data=open(r'datasets/orig/VLSP2018-SA-Restaurant-train.txt').read()\n","\n","opinions = data.split('\\n\\n')\n","    \n","sentences, tags_lst, sentiments_lst, lengths = [], [], [], []\n","#count = 0\n","for i in opinions:\n","    #count += 1\n","    splitt = i.split(\"\\n\")\n","    num, sentence, aspects = splitt[0], splitt[1], splitt[2]\n","    sentence = normalize(sentence)\n","    sentence = tokenize(sentence, model_tokenize)\n","    aspects = split_aspect(aspects)\n","    text_tags = [x[0] for x in aspects]\n","    sentiments = [x[1] for x in aspects]\n","    sentences.append(sentence)\n","    tags_lst.append(text_tags)\n","    sentiments_lst.append(sentiments)\n","    lengths.append(len(sentence.split()))\n","\n","no_sentences = len(sentences) \n","print(no_sentences)\n","print(max(lengths))\n","print(sum(lengths)/no_sentences)\n","\n","'''short_ids = [i for i in range(no_sentences) if lengths[i] <= 128]\n","\n","for i in range(no_sentences):\n","    if i not in short_ids:\n","        continue\n","    else:\n","        short_ids.remove(i)\n","        for j in range(no_sentences):\n","            if j in short_ids:\n","                cmm = [x for x in tags_lst[i] if x in tags_lst[j]]\n","                if len(cmm) == 0:\n","                    sentences.append(sentences[i] + \" \" + sentences[j])\n","                    tags_lst.append(tags_lst[i] + tags_lst[j])\n","                    sentiments_lst.append(sentiments_lst[i] + sentiments_lst[j])\n","                    lengths.append(lengths[i] + lengths[j])\n","                    short_ids.remove(j)\n","                    continue'''\n","                    \n","sentence_lst, targets= [], []\n","for i in range(len(sentences)):\n","    for tag in tag_dict:\n","        sentence = sentences[i] \n","        if tag not in tags_lst[i]:\n","            sentiment = polarity_dict['không có']\n","            target = \"Nhận_xét \" + tag_dict[tag] + \" \" + sentiment + \" .\"\n","            \n","        else:\n","            idx = tags_lst[i].index(tag)\n","            target = \"Nhận_xét \" + tag_dict[tag] + \" \" + polarity_dict[sentiments_lst[i][idx]]+ \" .\"\n","        sentence_lst.append(sentence)\n","        targets.append(target)\n","        \n","df = pd.DataFrame()\n","df['input_text'] = sentence_lst\n","df['target_text'] = targets\n","df.to_csv(\"bartpho_res_train.csv\", index = False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["data=open(r'datasets/orig/VLSP2018-SA-Restaurant-train.txt').read()\n","\n","opinions = data.split('\\n\\n')\n","    \n","sentences, tags_lst, sentiments_lst, lengths = [], [], [], []\n","#count = 0\n","for i in opinions:\n","    #count += 1\n","    splitt = i.split(\"\\n\")\n","    num, sentence, aspects = splitt[0], splitt[1], splitt[2]\n","    sentence = normalize(sentence)\n","    sentence = tokenize(sentence, model_tokenize)\n","    aspects = split_aspect(aspects)\n","    text_tags = [x[0] for x in aspects]\n","    sentiments = [x[1] for x in aspects]\n","    sentences.append(sentence)\n","    tags_lst.append(text_tags)\n","    sentiments_lst.append(sentiments)\n","    lengths.append(len(sentence.split()))\n","\n","no_sentences = len(sentences) \n","print(no_sentences)\n","print(max(lengths))\n","print(sum(lengths)/no_sentences)\n","\n","'''short_ids = [i for i in range(no_sentences) if lengths[i] <= 128]\n","\n","for i in range(no_sentences):\n","    if i not in short_ids:\n","        continue\n","    else:\n","        short_ids.remove(i)\n","        for j in range(no_sentences):\n","            if j in short_ids:\n","                cmm = [x for x in tags_lst[i] if x in tags_lst[j]]\n","                if len(cmm) == 0:\n","                    sentences.append(sentences[i] + \" \" + sentences[j])\n","                    tags_lst.append(tags_lst[i] + tags_lst[j])\n","                    sentiments_lst.append(sentiments_lst[i] + sentiments_lst[j])\n","                    lengths.append(lengths[i] + lengths[j])\n","                    short_ids.remove(j)\n","                    continue'''\n","                    \n","sentence_lst, targets= [], []\n","for i in range(len(sentences)):\n","    for tag in tag_dict:\n","        sentence = sentences[i] \n","        if tag not in tags_lst[i]:\n","            detect_target = tag_dict[tag] + \" không được nhận_xét .\"\n","            #sentiment = polarity_dict['không có']\n","            #target = \"Nhận_xét \" + tag_dict[tag] + \" \" + sentiment + \" .\"\n","            \n","        else:\n","            idx = tags_lst[i].index(tag)\n","            absa_target = \"Nhận_xét \" + tag_dict[tag] + \" \" + polarity_dict[sentiments_lst[i][idx]]+ \" .\"\n","            sentence_lst.append(sentence)\n","            targets.append(absa_target)\n","            detect_target = tag_dict[tag] + \" có được nhận_xét .\"\n","        sentence_lst.append(sentence)\n","        targets.append(detect_target)\n","        \n","df = pd.DataFrame()\n","df['input_text'] = sentence_lst\n","df['target_text'] = targets\n","df.to_csv(\"bartpho_res_train_detect.csv\", index = False)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["data=open(r'datasets/orig/VLSP2018-SA-Restaurant-train.txt').read()\n","opinions = data.split('\\n\\n')\n","sentences = []\n","aspect_cols = [[] for i in range(len(tags))]\n","\n","for i in opinions:\n","    splitt = i.split(\"\\n\")\n","    num, sentence, aspects = splitt[0], splitt[1], splitt[2]\n","    sentence = normalize(sentence)\n","    sentence = tokenize(sentence, model_tokenize)\n","    aspects = split_aspect(aspects)\n","    text_tags = [x[0] for x in aspects]\n","    sentiments = [x[1] for x in aspects]\n","    sentences.append(sentence)\n","    for j in range(len(tags)):\n","        tag = eng_tags[j]\n","        if tag not in text_tags:\n","            aspect_cols[j].append(0) \n","        else:\n","            idx = text_tags.index(tag)\n","            aspect_cols[j].append(eng_polarity.index(sentiments[idx]))\n","\n","df = pd.DataFrame()\n","df['text'] = sentences\n","for i in range(len(tags)):\n","    df[eng_tags[i]] = aspect_cols[i]\n","df.to_csv(\"res_train.csv\", index = False)\n","with open('sentences.json', 'w') as f:\n","    json.dump(sentences, f, ensure_ascii=False, indent=4)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"}},"nbformat":4,"nbformat_minor":4}
